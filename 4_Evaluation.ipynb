{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, r'C:\\Users\\Lukas\\OneDrive\\Dokumente\\projects\\invert')\n",
    "import mne\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from invert.evaluate import eval_mean_localization_error, eval_mean_localization_error_old\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from time import sleep\n",
    "from config import *\n",
    "\n",
    "os.makedirs('D:/data/flex_ssm/results', exist_ok=True)\n",
    "estimator = \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(fwd):\n",
    "    pos_left = mne.vertex_to_mni(fwd[\"src\"][0][\"vertno\"], 0, subject=subject, subjects_dir=subjects_dir, verbose=0)\n",
    "    pos_right = mne.vertex_to_mni(fwd[\"src\"][1][\"vertno\"], 1, subject=subject, subjects_dir=subjects_dir, verbose=0)\n",
    "    pos = np.concatenate([pos_left, pos_right], axis=0)\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Forward Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwds = {}\n",
    "fullpath = os.path.join(\"D:/data/flex_ssm/\", forward_models[0][\"path_fwd\"])\n",
    "fwd_ico4 = mne.read_forward_solution(fullpath, verbose=0)\n",
    "fwd_ico4 = mne.convert_forward_solution(fwd_ico4, force_fixed=True, surf_ori=True, use_cps=True)\n",
    "fwd_ico4.subject = \"sample\"\n",
    "pos_ico4 = get_pos(fwd_ico4)\n",
    "\n",
    "distances_ico4 = cdist(pos_ico4, pos_ico4)\n",
    "adjacency_ico4 = mne.spatial_src_adjacency(fwd_ico4[\"src\"], verbose=0).toarray()\n",
    "\n",
    "fullpath = os.path.join(\"D:/data/flex_ssm/\", forward_models[1][\"path_fwd\"])\n",
    "fwd_oct6 = mne.read_forward_solution(fullpath, verbose=0)\n",
    "fwd_oct6 = mne.convert_forward_solution(fwd_oct6, force_fixed=True, surf_ori=True, use_cps=True)\n",
    "fwd_oct6.subject = \"sample\"\n",
    "pos_oct6 = get_pos(fwd_oct6)\n",
    "distances_oct6 = cdist(pos_ico4, pos_oct6)\n",
    "adjacency_oct6 = mne.spatial_src_adjacency(fwd_oct6[\"src\"], verbose=0).toarray()\n",
    "\n",
    "fullpath = os.path.join(\"D:/data/flex_ssm/\", forward_models[0][\"path_info\"])\n",
    "with open(fullpath, \"rb\") as f:\n",
    "    info = pkl.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "idx = 100\n",
    "\n",
    "model = forward_models[1]\n",
    "fwd_test = mne.read_forward_solution(model[\"path_fwd\"], verbose=0)\n",
    "fwd_test = mne.convert_forward_solution(fwd_test, force_fixed=True)\n",
    "with open(model[\"path_info\"], \"rb\") as f:\n",
    "    info_test = pkl.load(f)\n",
    "data_1 = fwd_test[\"sol\"][\"data\"][:, idx][:, np.newaxis]\n",
    "\n",
    "evoked = mne.EvokedArray(data_1, info_test)\n",
    "evoked.plot_joint(title=model[\"name\"])\n",
    "\n",
    "model = forward_models[3]\n",
    "fwd_test = mne.read_forward_solution(model[\"path_fwd\"], verbose=0)\n",
    "fwd_test = mne.convert_forward_solution(fwd_test, force_fixed=True)\n",
    "with open(model[\"path_info\"], \"rb\") as f:\n",
    "    info_test = pkl.load(f)\n",
    "data_2 = fwd_test[\"sol\"][\"data\"][:, idx][:, np.newaxis]\n",
    "\n",
    "evoked = mne.EvokedArray(data_1, info_test)\n",
    "evoked.plot_joint(title=model[\"name\"])\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "print(pearsonr(data_1[:, 0], data_2[:, 0])[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.scatter(data_1[:, 0], data_2[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_evaluation = \"D:/data/flex_ssm/evaluation/\"\n",
    "eval_filenames = os.listdir(path_evaluation)\n",
    "adjacency_true = adjacency_ico4\n",
    "\n",
    "# eval_filenames = [f for f in eval_filenames if \"non-greedy\" in f]\n",
    "for i, filename in enumerate(eval_filenames):\n",
    "    # if not \"figure-4\" in filename:\n",
    "    #     continue\n",
    "    # print(filename)\n",
    "\n",
    "    fullpath = os.path.join(path_evaluation, filename)\n",
    "    figure = filename.split(\"_\")[3]\n",
    "    greedyness = fullpath.split(\"_\")[-1].split(\".\")[0]\n",
    "    model_error = fullpath.split(\"_\")[-2]\n",
    "    \n",
    "    if \"assumed\" in fullpath:\n",
    "        assumption = fullpath[:fullpath.find(\"assumed\")-1].split(\"_\")[-1]\n",
    "        assumed = f\"_{assumption}-assumed\"\n",
    "    else:\n",
    "        assumed = \"\"\n",
    "    \n",
    "    fn = f\"D:/data/flex_ssm/results/results_{figure}_{model_error}_{greedyness}{assumed}.pkl\"\n",
    "    print(fullpath, figure, greedyness, model_error)\n",
    "\n",
    "    \n",
    "    print(\"FN: \", fn)\n",
    "    if not \".pkl\" in filename or os.path.isfile(fn):\n",
    "        print(\"\\tis processed or not a regular file\")\n",
    "        continue\n",
    "    # break\n",
    "    with open(fullpath, \"rb\") as f:\n",
    "        stc_dict, x_test, y_test, sim_info, proc_time_make, proc_time_apply = pkl.load(f)\n",
    "    n_samples = len(y_test)\n",
    "    print(\"\\t\", fn)\n",
    "    if \"fine\" in filename.lower() or (not \"coarse\" in filename.lower() and not \"fine\" in filename.lower()):\n",
    "        print(\"\\t\\tyep\")\n",
    "        adjacency_pred = adjacency_oct6\n",
    "        distances = distances_oct6\n",
    "    else:\n",
    "        adjacency_pred = adjacency_ico4\n",
    "        distances = distances_ico4\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    for solver_name in stc_dict.keys():\n",
    "        print(solver_name)\n",
    "        for i in tqdm(range(n_samples)):\n",
    "            # y_pred = stc_dict[solver_name][i].data\n",
    "            y_pred = stc_dict[solver_name][i].toarray()\n",
    "            # y_true = y_test[i].T.toarray()\n",
    "            y_true = y_test[i].toarray()\n",
    "            # mle_dle = eval_mean_localization_error(abs(y_true).mean(axis=-1), abs(y_pred).mean(axis=-1), adjacency_true, adjacency_pred, distances, mode=\"dle\")\n",
    "            # mle_est = eval_mean_localization_error(abs(y_true).mean(axis=-1), abs(y_pred).mean(axis=-1), adjacency_true, adjacency_pred, distances, mode=\"est\")\n",
    "            # mle_true = eval_mean_localization_error(abs(y_true).mean(axis=-1), abs(y_pred).mean(axis=-1), adjacency_true, adjacency_pred, distances, mode=\"true\")\n",
    "            # mle_match = eval_mean_localization_error(abs(y_true).mean(axis=-1), abs(y_pred).mean(axis=-1), adjacency_true, adjacency_pred, distances, mode=\"match\")\n",
    "            mle_amir = eval_mean_localization_error(abs(y_true).mean(axis=-1), abs(y_pred).mean(axis=-1), adjacency_true, adjacency_pred, distances, mode=\"amir\")\n",
    "            result = dict(Method=solver_name, MLE_amir=mle_amir, Time_Make=proc_time_make[solver_name][i], Time_Apply=proc_time_apply[solver_name][i])\n",
    "            # result = dict(Method=solver_name, MLE_match=mle_match, MLE_dle=mle_dle, MLE_est=mle_est, MLE_true=mle_true, MLE_amir=mle_amir, Time_Make=proc_time_make[solver_name][i], Time_Apply=proc_time_apply[solver_name][i])\n",
    "            result.update(sim_info.iloc[i, :].to_dict())\n",
    "            results.append(result)\n",
    "            if i%100 == 0:\n",
    "                print(\"\\t \", i)\n",
    "    del stc_dict, y_test, proc_time_make, proc_time_apply\n",
    "    with open(fn, 'wb') as f:\n",
    "        pkl.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# filenames = os.listdir(\"results\")\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-1_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-1_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-1_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-1_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-1_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-1_Translation-Posterior-2_greedy.pkl'\n",
    "}\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    sns.barplot(hue=\"Method\", x=\"inter_source_correlations\", y=\"MLE\", data=df, errorbar=(\"ci\", 95), estimator=estimator)\n",
    "    plt.ylim(0, 18)\n",
    "    plt.title(title)\n",
    "    # save figure\n",
    "    savestring = re.sub('[+°.]', '', title).replace(\"  \", \" \").replace(\" \", \"_\")\n",
    "    \n",
    "    fig.savefig(f'figures/initial_results/Figure_1_{savestring}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 12  - 3 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# filenames = os.listdir(\"results\")\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-12_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-12_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-12_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-12_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-12_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-12_Translation-Posterior-2_greedy.pkl'\n",
    "}\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    sns.barplot(hue=\"Method\", x=\"inter_source_correlations\", y=\"MLE_dle\", data=df, errorbar=(\"ci\", 95), estimator=estimator)\n",
    "    plt.ylim(0, 28)\n",
    "    plt.title(title)\n",
    "    # save figure\n",
    "    savestring = re.sub('[+°.]', '', title).replace(\"  \", \" \").replace(\" \", \"_\")\n",
    "    \n",
    "    fig.savefig(f'figures/initial_results/Figure_12_{savestring}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 13  - Equal  Magnitude Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# filenames = os.listdir(\"results\")\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-13_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-13_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-13_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-13_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-13_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-13_Translation-Posterior-2_greedy.pkl'\n",
    "}\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    sns.barplot(hue=\"Method\", x=\"inter_source_correlations\", y=\"MLE_dle\", data=df, errorbar=(\"ci\", 95), estimator=estimator)\n",
    "    plt.ylim(0, 18)\n",
    "    plt.title(title)\n",
    "    # save figure\n",
    "    savestring = re.sub('[+°.]', '', title).replace(\"  \", \" \").replace(\" \", \"_\")\n",
    "    \n",
    "    fig.savefig(f'figures/initial_results/Figure_13_{savestring}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 14 - White Spectrum Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# filenames = os.listdir(\"results\")\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-14_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-14_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-14_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-14_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-14_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-14_Translation-Posterior-2_greedy.pkl'\n",
    "}\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    sns.barplot(hue=\"Method\", x=\"inter_source_correlations\", y=\"MLE_dle\", data=df, errorbar=(\"ci\", 95), estimator=estimator)\n",
    "    plt.ylim(0, 18)\n",
    "    plt.title(title)\n",
    "    # save figure\n",
    "    savestring = re.sub('[+°.]', '', title).replace(\"  \", \" \").replace(\" \", \"_\")\n",
    "    \n",
    "    fig.savefig(f'figures/initial_results/Figure_14_{savestring}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setup the figure and subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))  # Adjust the size as necessary\n",
    "axes = axes.flatten()  # Flatten the 2D array of axes to simplify accessing them\n",
    "\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-2_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-2_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-2_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-2_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-2_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-2_Translation-Posterior-2_greedy.pkl',\n",
    "    # Add additional filenames if needed to fill 3x3 grid\n",
    "}\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "estimator = \"median\"\n",
    "plot_idx = 0\n",
    "new_xticks = [-15, -10, -5, 0, 5]\n",
    "\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "    \n",
    "    # Remove the second SSM\n",
    "    results = [r for r in results if not \"Adaptive-Reg\" in r[\"Method\"]]\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Create each subplot\n",
    "    ax = axes[plot_idx]\n",
    "    sns.barplot(hue=\"Method\", x=\"snr\", y=\"MLE_match\", data=df, errorbar=(\"ci\", 95), estimator=estimator, ax=ax)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.set_title(title)\n",
    "    # change xtick labels\n",
    "    ax.set_xticks(new_xticks)\n",
    "    \n",
    "    plot_idx += 1\n",
    "\n",
    "\n",
    "# Adjust layout and save the entire figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{pth_results}/Figure_2_{estimator}.png', format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given some mne.io.Raw object, we could extract the first data points before the first event like so:\n",
    "# raw = mne.io.read_raw_fif(\"path/to/file.fif\")\n",
    "# raw.crop(tmax=raw.times[raw.annotations.onset[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# filenames = os.listdir(\"results\")\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-3_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-3_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-3_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-3_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-3_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-3_Translation-Posterior-2_greedy.pkl'\n",
    "}\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    sns.barplot(hue=\"Method\", x=\"n_timepoints\", y=\"MLE\", data=df, errorbar=(\"ci\", 95), estimator=estimator)\n",
    "    plt.ylim(0, 6)\n",
    "    plt.title(title)\n",
    "    # save figure\n",
    "    savestring = re.sub('[+°.]', '', title).replace(\"  \", \" \").replace(\" \", \"_\")\n",
    "    \n",
    "    fig.savefig(f'figures/initial_results/Figure_3_{savestring}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'filenames_' is defined as in your snippet above\n",
    "filenames_ = {\n",
    "    \"-1\": {\n",
    "        'No Error': 'results_figure-4_Clean-Coarse_greedy_-1-assumed.pkl',\n",
    "        'Source Modelling Error': 'results_figure-4_Clean-Fine_greedy_-1-assumed.pkl',\n",
    "        'SME + Rotation Right 1°': 'results_figure-4_Rotation-Right-1_greedy_-1-assumed.pkl',\n",
    "        'SME + Rotation Right 2°': 'results_figure-4_Rotation-Right-2_greedy_-1-assumed.pkl',\n",
    "        'SME + Translation Post. 1mm': 'results_figure-4_Translation-Posterior-1_greedy_-1-assumed.pkl',\n",
    "        'SME + Translation Post. 2mm': 'results_figure-4_Translation-Posterior-2_greedy_-1-assumed.pkl'\n",
    "    },\n",
    "    \"0\": {\n",
    "        'No Error': 'results_figure-4_Clean-Coarse_greedy_0-assumed.pkl',\n",
    "        'Source Modelling Error': 'results_figure-4_Clean-Fine_greedy_0-assumed.pkl',\n",
    "        'SME + Rotation Right 1°': 'results_figure-4_Rotation-Right-1_greedy_0-assumed.pkl',\n",
    "        'SME + Rotation Right 2°': 'results_figure-4_Rotation-Right-2_greedy_0-assumed.pkl',\n",
    "        'SME + Translation Post. 1mm': 'results_figure-4_Translation-Posterior-1_greedy_0-assumed.pkl',\n",
    "        'SME + Translation Post. 2mm': 'results_figure-4_Translation-Posterior-2_greedy_0-assumed.pkl'\n",
    "    },\n",
    "    \"1\": {\n",
    "        'No Error': 'results_figure-4_Clean-Coarse_greedy_1-assumed.pkl',\n",
    "        'Source Modelling Error': 'results_figure-4_Clean-Fine_greedy_1-assumed.pkl',\n",
    "        'SME + Rotation Right 1°': 'results_figure-4_Rotation-Right-1_greedy_1-assumed.pkl',\n",
    "        'SME + Rotation Right 2°': 'results_figure-4_Rotation-Right-2_greedy_1-assumed.pkl',\n",
    "        'SME + Translation Post. 1mm': 'results_figure-4_Translation-Posterior-1_greedy_1-assumed.pkl',\n",
    "        'SME + Translation Post. 2mm': 'results_figure-4_Translation-Posterior-2_greedy_1-assumed.pkl'\n",
    "    },\n",
    "}\n",
    "\n",
    "# Set the theme for seaborn\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Row and column titles\n",
    "row_titles = ['-1', '0', '1'] # Assumed sources\n",
    "column_titles = [\n",
    "    'No Error', 'Source Modelling Error', 'SME + Rotation Right 1°',\n",
    "    'SME + Rotation Right 2°', 'SME + Translation Post. 1mm', 'SME + Translation Post. 2mm'\n",
    "]\n",
    "\n",
    "metrics_description = {\n",
    "    \"Dipole Localization Error\": \"MLE_dle\",\n",
    "    \"Localization Error (True)\": \"MLE_true\",\n",
    "    \"Localization Error (Estimated)\": \"MLE_est\",\n",
    "    \"Matched Localization Error\": \"MLE_match\"\n",
    "    }\n",
    "\n",
    "for suptitle, y_var in metrics_description.items():\n",
    "    # Create a subplot grid: 3 rows x 6 columns\n",
    "    fig, axes = plt.subplots(3, 6, figsize=(20, 10), sharex='col', sharey='row')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4) # Adjust space between plots\n",
    "    # Iterate over each assumption and filenames\n",
    "    for i, (assumption, filenames) in enumerate(filenames_.items()):\n",
    "        if assumption == \"-1\":\n",
    "            assumption_text = \"1 source less\"\n",
    "        elif assumption == \"0\":\n",
    "            assumption_text = \"Correct number of sources\"\n",
    "        elif assumption == \"1\":\n",
    "            assumption_text = \"1 source more\"\n",
    "\n",
    "        for j, (title, filename) in enumerate(filenames.items()):\n",
    "            ax = axes[i, j] # Current subplot axis\n",
    "            filename = os.path.join(\"results\", filename)\n",
    "            if not os.path.isfile(filename):\n",
    "                ax.text(0.5, 0.5, f\"{filename} does not exist\", ha='center')\n",
    "                continue\n",
    "            with open(filename, 'rb') as f:\n",
    "                results = pkl.load(f)\n",
    "\n",
    "            df = pd.DataFrame(results)\n",
    "\n",
    "            # Plot on the specified subplot axis\n",
    "            sns.barplot(\n",
    "                hue=\"Method\", x=\"inter_source_correlations\", y=y_var, data=df, \n",
    "                errorbar=(\"ci\", 95), estimator=estimator, ax=ax\n",
    "            )\n",
    "\n",
    "            # Set row and column titles\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(assumption_text + \"\\n\\n\" + \"Mean Localization Error [mm]\")\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "            \n",
    "            if i == 2:\n",
    "                ax.set_xlabel('Inter-source Correlations')\n",
    "            else:\n",
    "                ax.set_xlabel('')\n",
    "\n",
    "            # Set the title for the first row and remove from others\n",
    "            if i == 0:\n",
    "                ax.set_title(column_titles[j])\n",
    "            else:\n",
    "                ax.set_title('')\n",
    "            \n",
    "            # Remove legend if not 0th column\n",
    "            if j != 0:\n",
    "                ax.get_legend().remove()\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'figures/initial_results/Figure_4_{y_var}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Figure 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'filenames_' is defined as in your snippet above\n",
    "filenames_ = {\n",
    "    \"-1\": {\n",
    "        'No Error': 'D:/data/flex_ssm/results/results_figure-42_Clean-Coarse_greedy_-1-assumed.pkl',\n",
    "        'Source Modelling Error': 'D:/data/flex_ssm/results/results_figure-42_Clean-Fine_greedy_-1-assumed.pkl',\n",
    "        'SME + Rotation Right 1°': 'D:/data/flex_ssm/results/results_figure-42_Rotation-Right-1_greedy_-1-assumed.pkl',\n",
    "        'SME + Rotation Right 2°': 'D:/data/flex_ssm/results/results_figure-42_Rotation-Right-2_greedy_-1-assumed.pkl',\n",
    "        'SME + Translation Post. 1mm': 'D:/data/flex_ssm/results/results_figure-42_Translation-Posterior-1_greedy_-1-assumed.pkl',\n",
    "        'SME + Translation Post. 2mm': 'D:/data/flex_ssm/results/results_figure-42_Translation-Posterior-2_greedy_-1-assumed.pkl'\n",
    "    },\n",
    "    \"0\": {\n",
    "        'No Error': 'D:/data/flex_ssm/results/results_figure-42_Clean-Coarse_greedy_0-assumed.pkl',\n",
    "        'Source Modelling Error': 'D:/data/flex_ssm/results/results_figure-42_Clean-Fine_greedy_0-assumed.pkl',\n",
    "        'SME + Rotation Right 1°': 'D:/data/flex_ssm/results/results_figure-42_Rotation-Right-1_greedy_0-assumed.pkl',\n",
    "        'SME + Rotation Right 2°': 'D:/data/flex_ssm/results/results_figure-42_Rotation-Right-2_greedy_0-assumed.pkl',\n",
    "        'SME + Translation Post. 1mm': 'D:/data/flex_ssm/results/results_figure-42_Translation-Posterior-1_greedy_0-assumed.pkl',\n",
    "        'SME + Translation Post. 2mm': 'D:/data/flex_ssm/results/results_figure-42_Translation-Posterior-2_greedy_0-assumed.pkl'\n",
    "    },\n",
    "    \"1\": {\n",
    "        'No Error': 'D:/data/flex_ssm/results/results_figure-42_Clean-Coarse_greedy_1-assumed.pkl',\n",
    "        'Source Modelling Error': 'D:/data/flex_ssm/results/results_figure-42_Clean-Fine_greedy_1-assumed.pkl',\n",
    "        'SME + Rotation Right 1°': 'D:/data/flex_ssm/results/results_figure-42_Rotation-Right-1_greedy_1-assumed.pkl',\n",
    "        'SME + Rotation Right 2°': 'D:/data/flex_ssm/results/results_figure-42_Rotation-Right-2_greedy_1-assumed.pkl',\n",
    "        'SME + Translation Post. 1mm': 'D:/data/flex_ssm/results/results_figure-42_Translation-Posterior-1_greedy_1-assumed.pkl',\n",
    "        'SME + Translation Post. 2mm': 'D:/data/flex_ssm/results/results_figure-42_Translation-Posterior-2_greedy_1-assumed.pkl'\n",
    "    },\n",
    "}\n",
    "\n",
    "# Set the theme for seaborn\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Row and column titles\n",
    "row_titles = ['-1', '0', '1'] # Assumed sources\n",
    "column_titles = [\n",
    "    'No Error', 'Source Modelling Error', 'SME + Rotation Right 1°',\n",
    "    'SME + Rotation Right 2°', 'SME + Translation Post. 1mm', 'SME + Translation Post. 2mm'\n",
    "]\n",
    "\n",
    "metrics_description = {\n",
    "    # \"Dipole Localization Error\": \"MLE_dle\",\n",
    "    # \"Localization Error (True)\": \"MLE_true\",\n",
    "    # \"Localization Error (Estimated)\": \"MLE_est\",\n",
    "    # \"Matched Localization Error\": \"MLE_match\",\n",
    "    \"Amirs Matched Localization Error\": \"MLE_amir\"\n",
    "    }\n",
    "\n",
    "for suptitle, y_var in metrics_description.items():\n",
    "    # Create a subplot grid: 3 rows x 6 columns\n",
    "    fig, axes = plt.subplots(3, 6, figsize=(20, 10), sharex='col', sharey='row')\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4) # Adjust space between plots\n",
    "    # Iterate over each assumption and filenames\n",
    "    for i, (assumption, filenames) in enumerate(filenames_.items()):\n",
    "        if assumption == \"-1\":\n",
    "            assumption_text = \"1 source less\"\n",
    "        elif assumption == \"0\":\n",
    "            assumption_text = \"Correct number of sources\"\n",
    "        elif assumption == \"1\":\n",
    "            assumption_text = \"1 source more\"\n",
    "\n",
    "        for j, (title, filename) in enumerate(filenames.items()):\n",
    "            ax = axes[i, j] # Current subplot axis\n",
    "            filename = os.path.join(\"results\", filename)\n",
    "            if not os.path.isfile(filename):\n",
    "                ax.text(0.5, 0.5, f\"{filename} does not exist\", ha='center')\n",
    "                continue\n",
    "            with open(filename, 'rb') as f:\n",
    "                results = pkl.load(f)\n",
    "\n",
    "            df = pd.DataFrame(results)\n",
    "\n",
    "            # Plot on the specified subplot axis\n",
    "            sns.barplot(\n",
    "                hue=\"Method\", x=\"inter_source_correlations\", y=y_var, data=df, \n",
    "                errorbar=(\"ci\", 95), estimator=estimator, ax=ax\n",
    "            )\n",
    "\n",
    "            # Set row and column titles\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(assumption_text + \"\\n\\n\" + \"Mean Localization Error [mm]\")\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "            \n",
    "            if i == 2:\n",
    "                ax.set_xlabel('Inter-source Correlations')\n",
    "            else:\n",
    "                ax.set_xlabel('')\n",
    "\n",
    "            # Set the title for the first row and remove from others\n",
    "            if i == 0:\n",
    "                ax.set_title(column_titles[j])\n",
    "            else:\n",
    "                ax.set_title('')\n",
    "            \n",
    "            # Remove legend if not 0th column\n",
    "            if j != 0:\n",
    "                ax.get_legend().remove()\n",
    "                \n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'D:/data/flex_ssm/figures/initial_results/Figure_42_{y_var}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "# three strong colors and three light colors with same tone (seaborn)\n",
    "colors = [\"#4c72b0\", \"#55a868\", \"#c44e52\", \"#8172b2\", \"#ccb974\", \"#64b5cd\"]\n",
    "\n",
    "# filenames = os.listdir(\"results\")\n",
    "filenames = {\n",
    "    'No Error': 'results_figure-5_Clean-Coarse_greedy.pkl',\n",
    "    'Source Modelling Error': 'results_figure-5_Clean-Fine_greedy.pkl',\n",
    "    'SME + Rotation Right 1°': 'results_figure-5_Rotation-Right-1_greedy.pkl',\n",
    "    'SME + Rotation Right 2°': 'results_figure-5_Rotation-Right-2_greedy.pkl',\n",
    "    'SME + Translation Post. 1mm': 'results_figure-5_Translation-Posterior-1_greedy.pkl',\n",
    "    'SME + Translation Post. 2mm': 'results_figure-5_Translation-Posterior-2_greedy.pkl'\n",
    "}\n",
    "for title, filename in filenames.items():\n",
    "    filename = os.path.join(\"results\", filename)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"{filename} does not exist\")\n",
    "        continue\n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"n_orders\"] = [ii[0] for ii in df[\"n_orders\"].values]\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    sns.barplot(hue=\"Method\", x=\"n_orders\", y=\"MLE_dle\", data=df, errorbar=(\"ci\", 95), estimator=estimator, palette=colors)\n",
    "    # sns.barplot(hue=\"Method\", x=\"n_orders\", y=\"MLE_dle\", data=df, errorbar=(\"ci\", 95), estimator=\"mean\", palette=colors)\n",
    "    plt.ylim(0, 12)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Mean Localization Error [mm]\")\n",
    "\n",
    "    # save figure\n",
    "    savestring = re.sub('[+°.]', '', title).replace(\"  \", \" \").replace(\" \", \"_\")\n",
    "    fig.savefig(f'figures/initial_results/Figure_5_{savestring}_{estimator}s.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import mne\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from config import forward_models\n",
    "pp = dict(surface=\"inflated\", hemi=\"both\", subject=\"sample\", cortex=\"low_contrast\")\n",
    "\n",
    "fn = r\"C:\\Users\\lukas\\Dokumente\\projects\\flex_ssm\\ssm_paper_analysis\\evaluation\\sim_and_preds_figure-1_Clean-Fine_greedy.pkl\"\n",
    "with open(fn, \"rb\") as f:\n",
    "    stc, stc_dict, x_test, y_test, sim_info, proc_time_make, proc_time_apply = pkl.load(f)\n",
    "\n",
    "fwd_coarse = mne.read_forward_solution(forward_models[0][\"path_fwd\"], verbose=0)\n",
    "fwd_fine = mne.read_forward_solution(forward_models[1][\"path_fwd\"], verbose=0)\n",
    "# convert to fixed\n",
    "fwd_coarse = mne.convert_forward_solution(fwd_coarse, surf_ori=True, force_fixed=True, use_cps=True, verbose=0)\n",
    "fwd_fine = mne.convert_forward_solution(fwd_fine, surf_ori=True, force_fixed=True, use_cps=True, verbose=0)\n",
    "leadfield = deepcopy(fwd_fine[\"sol\"][\"data\"])\n",
    "leadfield /= np.linalg.norm(leadfield, axis=0)\n",
    "with open(forward_models[0][\"path_info\"], \"rb\") as f:\n",
    "    info = pkl.load(f)\n",
    "\n",
    "\n",
    "subjects_dir = r\"C:\\Users\\lukas\\mne_data\\MNE-sample-data\\subjects\"\n",
    "subject = \"sample\"\n",
    "\n",
    "# src_coarse = mne.setup_source_space(subject, spacing=\"ico4\", surface='white',\n",
    "#                                         subjects_dir=subjects_dir, add_dist=False,\n",
    "#                                         n_jobs=-1, verbose=0)\n",
    "# src_fine = mne.setup_source_space(subject, spacing=\"oct6\", surface='white',\n",
    "#                                         subjects_dir=subjects_dir, add_dist=False,\n",
    "#                                         n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "idx = 5\n",
    "\n",
    "stc = mne.SourceEstimate(y_test[idx].toarray().T, vertices=[fwd_coarse[\"src\"][0][\"vertno\"], fwd_coarse[\"src\"][1][\"vertno\"]], tmin=0, tstep=1, subject=\"sample\")\n",
    "stc.subject = \"sample\"\n",
    "stc.plot(brain_kwargs=dict(title=f\"Ground Truth sample {idx}\"), **pp)\n",
    "evoked = mne.EvokedArray(x_test[idx].T, info)\n",
    "evoked.plot_joint(title=\"Ground Truth\")\n",
    "\n",
    "solver = \"SSM\"\n",
    "J = stc_dict[solver][idx].toarray()\n",
    "stc = mne.SourceEstimate(J, vertices=[fwd_fine[\"src\"][0][\"vertno\"], fwd_fine[\"src\"][1][\"vertno\"]], tmin=0, tstep=1, subject=\"sample\")\n",
    "stc.subject = \"sample\"\n",
    "stc.plot(brain_kwargs=dict(title=f\"{solver} sample {idx}\"), **pp)\n",
    "x_hat = leadfield @ J\n",
    "evoked = mne.EvokedArray(x_hat, info)\n",
    "evoked.plot_joint(title=solver)\n",
    "\n",
    "solver = \"AP\"\n",
    "J = stc_dict[solver][idx].toarray()\n",
    "stc = mne.SourceEstimate(J, vertices=[fwd_fine[\"src\"][0][\"vertno\"], fwd_fine[\"src\"][1][\"vertno\"]], tmin=0, tstep=1, subject=\"sample\")\n",
    "stc.subject = \"sample\"\n",
    "stc.plot(brain_kwargs=dict(title=f\"{solver} sample {idx}\"), **pp)\n",
    "x_hat = leadfield @ J\n",
    "evoked = mne.EvokedArray(x_hat, info)\n",
    "evoked.plot_joint(title=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def localization_error_metric(true_positions, estimated_positions):\n",
    "    \"\"\"\n",
    "    Calculate the localization error between the estimated and true dipole locations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    true_positions : np.ndarray, shape (n_true_dipoles, 3)\n",
    "        The true positions of the dipoles.\n",
    "    estimated_positions : np.ndarray, shape (n_estimated_dipoles, 3)\n",
    "        The estimated positions of the dipoles.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_distance : float\n",
    "        The sum of distances between the true and estimated dipole positions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the distance matrix between all pairs of true and estimated positions\n",
    "    distance_matrix = np.linalg.norm(true_positions[:, np.newaxis] - estimated_positions, axis=2)\n",
    "    \n",
    "    # Solve the assignment problem (i.e., find the matching with minimum total distance)\n",
    "    true_indices, estimated_indices = linear_sum_assignment(distance_matrix)\n",
    "    \n",
    "    # Calculate the sum of distances for the optimal assignment\n",
    "    mean_distance = distance_matrix[true_indices, estimated_indices].mean()\n",
    "    \n",
    "    return mean_distance\n",
    "    \n",
    "# Example usage:\n",
    "true_dipole_positions = np.array(\n",
    "    [\n",
    "        [-20, 31, 19],\n",
    "        [24, 29, 21],\n",
    "        # [28, -20, 21],\n",
    "    ]\n",
    ")\n",
    "\n",
    "estimated_dipole_positions = np.array(\n",
    "    [\n",
    "        [-19, 25, 19],\n",
    "        [24, 27, 22],\n",
    "        # [30, -20, 22],\n",
    "        [100, 100,100]\n",
    "    ]\n",
    ")\n",
    "error = localization_error_metric(true_dipole_positions, estimated_dipole_positions)\n",
    "print(\"Total localization error:\", error)\n",
    "# print(\"Matching estimated dipoles to true dipoles:\", matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "cdist(true_dipole_positions, estimated_dipole_positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invertenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda1e5657e486f74a7b39841fb8103db2af51a77394f44c39a7821a371af47bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
